embedding:
  model_name: sentence-transformers/all-roberta-large-v1 
  normalize: true
  min_dimension: 1024
  api_provider: huggingface
  model_dimension: 1024
  encode_kwargs:
    normalize_embeddings: true

backend:
  chroma_dir: ./.chroma
  collection_name: code_index
  persist_directory: ./.chroma

indexing:
  local_repo_root: ./repos
  local_paths: ["./repos/cds-web"]
  include_globs: ["**/*"]
  exclude_globs: ["**/.git/**","**/.github/**","**/node_modules/**","**/dist/**","**/build/**","**/*.min.js","**/*.png","**/*.jpg","**/*.jpeg","**/*.pdf"]
  max_file_mb: 2.0  # Increased for better context
  chunk_size: 1500  # Increased chunk size for more context
  chunk_overlap: 200  # Increased overlap for better continuity
  batch_size: 2000
  github_token_env: GITHUB_TOKEN
  github_auth_required: false
  max_retries: 3
  timeout: 30
  force_reindex: true

retrieval:
  top_k: 20  # Increased for more comprehensive results
  alpha_hybrid: 0.3
  use_reranker: true
  cross_encoder_model: cross-encoder/ms-marco-MiniLM-L-6-v2
  similarity_threshold: 0.4  # Lowered for more inclusive results
  max_context_docs: 30  # Maximum documents to consider for context
  include_file_context: true  # Include related files in context
  boost_same_language: true  # Boost results from same programming language

server:
  host: 0.0.0.0
  port: 8000

chat:
  provider: gemini
  model: gemini-1.5-flash
  temperature: 0.1
  api_key_env: GEMINI_API_KEY
  max_tokens: 4096

current_method: gemini
app_env: local

# Alternative OpenAI configuration (uncomment to use):
# chat:
#   provider: openai
#   model: gpt-3.5-turbo
#   temperature: 0.1
#   api_key_env: OPENAI_API_KEY
#   max_tokens: 4096
# current_method: openai

logging:
  level: INFO
  file: ./logs/app.log